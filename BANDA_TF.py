"""An Example of a DNNClassifier for the Iris dataset."""
from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

import argparse
import tensorflow as tf

import bandaTF_data


parser = argparse.ArgumentParser()
parser.add_argument('--batch_size', default=100, type=int, help='batch size')
parser.add_argument('--train_steps', default=1000, type=int,
                    help='number of training steps')

def main(argv):
    args = parser.parse_args(argv[1:])

    # Fetch the data
    (train_x, train_y), (test_x, test_y) = bandaTF_data.load_data()

    # Feature columns describe how to use the input.
    my_feature_columns = []
    for key in train_x.keys():
        my_feature_columns.append(tf.feature_column.numeric_column(key=key))

    # Build 2 hidden layer DNN with 10, 10 units respectively.
    classifier = tf.estimator.DNNClassifier(
        feature_columns=my_feature_columns,
        # Two hidden layers of 10 nodes each.
        hidden_units=[10000,1000,100],
        # The model must choose between 3 classes.
        n_classes=2)

    # Train the Model.
    classifier.train(
        input_fn=lambda:bandaTF_data.train_input_fn(train_x, train_y,
                                                 args.batch_size),
        steps=args.train_steps)

    # Evaluate the model.
    eval_result = classifier.evaluate(
        input_fn=lambda:bandaTF_data.eval_input_fn(test_x, test_y,
                                                args.batch_size))

    print('\nTest set accuracy: {accuracy:0.3f}\n'.format(**eval_result))

    # Generate predictions from the model
    expected = [0,0,1,0,1] #,'NonAnhedonic','Anhedonic']
    predict_x = {'FA11101101': [0.34445500000000001, 0.32546999999999998, 0.34622999999999998, 0.28329700000000002, 0.323739], 'FA1110110000': [0.301371, 0.28823100000000001, 0.33563199999999999, 0.32167299999999999, 0.31509199999999998], 'FA1110110001': [0.29408699999999999, 0.298406, 0.30830299999999999, 0.28551799999999999, 0.28133799999999998], 'FA1110110010': [0.25766499999999998, 0.298875, 0.33457900000000002, 0.32333800000000001, 0.30227300000000001], 'FA1110110011': [0.28098299999999998, 0.26558199999999998, 0.31710300000000002, 0.28081800000000001, 0.29055199999999998], 'FA111111000': [0.35699199999999998, 0.373973, 0.31484699999999999, 0.32410099999999997, 0.37706499999999998], 'FA111111001': [0.37485600000000002, 0.37479600000000002, 0.360093, 0.33553100000000002, 0.30926100000000001], 'FA111111010': [0.28903600000000002, 0.283169, 0.351989, 0.27870800000000001, 0.248366], 'FA111111011': [0.26522000000000001, 0.25364799999999998, 0.27691300000000002, 0.25833099999999998, 0.279026], 'MD11101101': [0.61574499999999999, 0.64718399999999998, 0.60308300000000004, 0.64948799999999995, 0.62715200000000004], 'MD1110110000': [0.61824900000000005, 0.62353099999999995, 0.58747499999999997, 0.62069200000000002, 0.61736999999999997], 'MD1110110001': [0.63416899999999998, 0.62159299999999995, 0.61009000000000002, 0.64086799999999999, 0.62757700000000005], 'MD1110110010': [0.64954000000000001, 0.62460700000000002, 0.59353100000000003, 0.62795400000000001, 0.64836300000000002], 'MD1110110011': [0.62546299999999999, 0.63783800000000002, 0.60607500000000003, 0.64198999999999995, 0.62658199999999997], 'MD111111000': [0.57408400000000004, 0.59044399999999997, 0.62414000000000003, 0.62265499999999996, 0.58325099999999996], 'MD111111001': [0.57308000000000003, 0.58296700000000001, 0.57890900000000001, 0.59626500000000004, 0.61479899999999998], 'MD111111010': [0.58123899999999995, 0.59885200000000005, 0.61478600000000005, 0.632942, 0.63957200000000003], 'MD111111011': [0.599881, 0.60758500000000004, 0.635772, 0.63244800000000001, 0.61943499999999996], 'RD11101101': [0.49754999999999999, 0.532524, 0.48969000000000001, 0.55071999999999999, 0.51357399999999997], 'RD1110110000': [0.51922299999999999, 0.53002199999999999, 0.48164000000000001, 0.51226799999999995, 0.51185999999999998], 'RD1110110001': [0.53676500000000005, 0.52291600000000005, 0.511019, 0.54324700000000004, 0.53461899999999996], 'RD1110110010': [0.56420499999999996, 0.52701799999999999, 0.487819, 0.51826799999999995, 0.542489], 'RD1110110011': [0.53417000000000003, 0.54913999999999996, 0.50514499999999996, 0.54670099999999999, 0.530246], 'RD111111000': [0.458287, 0.46243899999999999, 0.51849699999999999, 0.51184499999999999, 0.45803500000000003], 'RD111111001': [0.44982, 0.45618500000000001, 0.46212999999999999, 0.48613699999999999, 0.51056699999999999], 'RD111111010': [0.48630699999999999, 0.50483900000000004, 0.49727700000000002, 0.53887300000000005, 0.55539099999999997], 'RD111111011': [0.50982899999999998, 0.51992700000000003, 0.54308000000000001, 0.54428200000000004, 0.52589900000000001], 'AD11101101': [0.85213399999999995, 0.87650499999999998, 0.82986800000000005, 0.84702299999999997, 0.85430700000000004], 'AD1110110000': [0.81630199999999997, 0.81055100000000002, 0.79914600000000002, 0.837538, 0.82839099999999999], 'AD1110110001': [0.82897600000000005, 0.81894599999999995, 0.80823199999999995, 0.83611199999999997, 0.81349400000000005], 'AD1110110010': [0.82020999999999999, 0.81978499999999999, 0.80495700000000003, 0.84732799999999997, 0.86011099999999996], 'AD1110110011': [0.80804900000000002, 0.81523500000000004, 0.80793599999999999, 0.83256699999999995, 0.81925400000000004], 'AD111111000': [0.80567900000000003, 0.84645499999999996, 0.83542799999999995, 0.84427600000000003, 0.83368399999999998], 'AD111111001': [0.81960100000000002, 0.83653299999999997, 0.81246799999999997, 0.81652100000000005, 0.823264], 'AD111111010': [0.77110199999999995, 0.78687600000000002, 0.84980500000000003, 0.82108099999999995, 0.80793400000000004], 'AD111111011': [0.77998500000000004, 0.78290099999999996, 0.82115700000000003, 0.80878000000000005, 0.80650500000000003]}


    """ predict_x = {
    'FA': [0.31, 0.30],
    'MD': [0.62, 0.60],
    'RD': [0.51, 0.50],
    'AD': [0.83, 0.81],
    }
    """

    predictions = classifier.predict(
        input_fn=lambda:bandaTF_data.eval_input_fn(predict_x,
                                                labels=None,
                                                batch_size=args.batch_size))

    template = ('\nPrediction is "{}" ({:.1f}%), expected "{}"')

    for pred_dict, expec in zip(predictions, expected):
        class_id = pred_dict['class_ids'][0]
        probability = pred_dict['probabilities'][class_id]

        print(template.format(bandaTF_data.SPECIES[class_id],
                              100 * probability, expec))

if __name__ == '__main__':
    tf.logging.set_verbosity(tf.logging.INFO)
    tf.app.run(main)
